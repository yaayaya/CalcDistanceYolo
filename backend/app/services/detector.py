#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO åµæ¸¬æœå‹™ - æ ¸å¿ƒåµæ¸¬å¼•æ“
"""

import asyncio
import cv2
import time
import base64
import numpy as np
from collections import deque
from typing import Optional, Dict, Any, AsyncGenerator
from ultralytics import YOLO

from .calculator import DistanceCalculator
from ..utils.config_loader import load_sensor_config, get_model_path, load_project_config


class YOLODetectorService:
    """
    YOLO11 åµæ¸¬æœå‹™
    è² è²¬æ”å½±æ©Ÿç®¡ç†ã€YOLO æ¨è«–ã€è·é›¢è¨ˆç®—
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åµæ¸¬æœå‹™"""
        self.config = load_sensor_config()
        self.project_config = load_project_config()
        self.model: Optional[YOLO] = None
        self.cap: Optional[cv2.VideoCapture] = None
        self.is_running = False
        
        # è·é›¢è¨ˆç®—å™¨
        self.distance_calculator = DistanceCalculator(self.config["distance"])
        
        # çµ±è¨ˆè³‡æ–™
        self.fps = 0
        self.actual_fps = 0
        self.total_detections = 0
        self.closest_distance = 0.0
        self.frame_times = deque(maxlen=30)
        self.start_time: Optional[float] = None
        
        # ç•¶å‰åµæ¸¬çµæœå¿«ç…§ (ä¾› REST API ä½¿ç”¨)
        self.current_snapshot: Optional[Dict[str, Any]] = None
        
        # æœ€æ–°å½±åƒå¹€ (ä¾› Flur ä¸²æµä½¿ç”¨)
        self.current_frame: Optional[np.ndarray] = None
        
    def load_model(self):
        """è¼‰å…¥ YOLO æ¨¡å‹"""
        if self.model is not None:
            return
            
        try:
            model_path = get_model_path()
            self.model = YOLO(str(model_path))
            
            # å¾ project_config è®€å–è¨­å‚™è¨­å®š
            device = self.project_config.get("yolo_device", {}).get("device", "cpu")
            print(f"âœ… YOLO æ¨¡å‹å·²è¼‰å…¥: {model_path} (è¨­å‚™: {device})")
        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•è¼‰å…¥ YOLO æ¨¡å‹: {e}")
    
    def start_camera(self):
        """å•Ÿå‹•æ”å½±æ©Ÿ"""
        if self.cap is not None and self.cap.isOpened():
            return
            
        try:
            source = self.config["camera"]["source"]
            self.cap = cv2.VideoCapture(source)
            
            if not self.cap.isOpened():
                raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ: {source}")
            
            # è¨­å®šè§£æåº¦
            width = self.config["camera"]["width"]
            height = self.config["camera"]["height"]
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            
            print(f"âœ… æ”å½±æ©Ÿå·²å•Ÿå‹•: {source} ({width}x{height})")
        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•å•Ÿå‹•æ”å½±æ©Ÿ: {e}")
    
    def stop_camera(self):
        """åœæ­¢æ”å½±æ©Ÿ"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
            print("â¹ æ”å½±æ©Ÿå·²åœæ­¢")
    
    def rotate_frame(self, frame, angle):
        """
        æ—‹è½‰å½±åƒ
        
        Args:
            frame: è¼¸å…¥å½±åƒ
            angle: æ—‹è½‰è§’åº¦ (0, 90, 180, 270)
        
        Returns:
            æ—‹è½‰å¾Œçš„å½±åƒ
        """
        if angle == 0:
            return frame
        elif angle == 90:
            return cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        elif angle == 180:
            return cv2.rotate(frame, cv2.ROTATE_180)
        elif angle == 270:
            return cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        else:
            return frame
    
    async def start_detection(self):
        """å•Ÿå‹•åµæ¸¬"""
        if self.is_running:
            return
            
        self.load_model()
        self.start_camera()
        self.is_running = True
        self.start_time = time.time()
        print("â–¶ åµæ¸¬å™¨å·²å•Ÿå‹•")
    
    async def stop_detection(self):
        """åœæ­¢åµæ¸¬"""
        self.is_running = False
        self.stop_camera()
        self.start_time = None
        print("â¹ åµæ¸¬å™¨å·²åœæ­¢")
    
    async def detection_stream(self) -> AsyncGenerator[Dict[str, Any], None]:
        """
        åµæ¸¬ä¸²æµ - ç•°æ­¥ç”Ÿæˆå™¨
        æŒçºŒç”¢ç”Ÿåµæ¸¬çµæœç›´åˆ° is_running ç‚º False
        
        Yields:
            åµæ¸¬çµæœå­—å…¸,åŒ…å« detections, fps, closest_distance, total_count, timestamp
        """
        if not self.is_running:
            await self.start_detection()
        
        frame_count = 0
        fps_start = time.time()
        fps_counter = 0
        last_frame_time = time.time()
        
        # FPS é™åˆ¶åƒæ•¸
        use_fps_limit = self.config["performance"]["use_fps_limit"]
        target_fps = self.config["performance"]["target_fps"]
        frame_interval = 1.0 / target_fps if use_fps_limit else 0
        vid_stride = self.config["model"]["vid_stride"]
        
        loop = asyncio.get_event_loop()
        
        while self.is_running:
            try:
                loop_start = time.time()
                
                # === è®€å–å½±åƒ (åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œ,é¿å…é˜»å¡) ===
                ret, frame = await loop.run_in_executor(None, self.cap.read)
                
                if not ret:
                    print("âš  ç„¡æ³•è®€å–å½±åƒ,å˜—è©¦é‡æ–°é€£æ¥...")
                    await asyncio.sleep(1)
                    continue
                
                # === å¥—ç”¨æ—‹è½‰ ===
                rotation_angle = self.config["camera"].get("rotation", 0)
                if rotation_angle != 0:
                    frame = self.rotate_frame(frame, rotation_angle)
                
                # å„²å­˜ç•¶å‰å¹€ä¾› Flur ä¸²æµä½¿ç”¨
                self.current_frame = frame.copy()
                
                frame_count += 1
                
                # === è·³å¹€è™•ç† ===
                if frame_count % vid_stride != 0:
                    continue
                
                # === YOLO æ¨è«– (åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œ) ===
                results = await loop.run_in_executor(
                    None,
                    self._run_yolo_inference,
                    frame
                )
                
                # === è™•ç†åµæ¸¬çµæœ ===
                detection_data = self._process_results(results)
                
                # === FPS è¨ˆç®— ===
                fps_counter += 1
                if time.time() - fps_start >= 1.0:
                    self.fps = fps_counter
                    fps_counter = 0
                    fps_start = time.time()
                
                # === å¯¦éš› FPS (å«è™•ç†æ™‚é–“) ===
                frame_time = time.time() - last_frame_time
                self.frame_times.append(frame_time)
                avg_frame_time = np.mean(self.frame_times)
                self.actual_fps = int(1.0 / avg_frame_time) if avg_frame_time > 0 else 0
                last_frame_time = time.time()
                
                # === æ›´æ–°çµ±è¨ˆè³‡æ–™ ===
                detection_data["fps"] = self.fps
                detection_data["actual_fps"] = self.actual_fps
                detection_data["timestamp"] = time.time()
                
                # æ›´æ–°å¿«ç…§
                self.current_snapshot = detection_data
                
                # === ç”¢ç”Ÿçµæœ ===
                yield detection_data
                
                # === FPS é™åˆ¶ ===
                if use_fps_limit:
                    elapsed_time = time.time() - loop_start
                    sleep_time = frame_interval - elapsed_time
                    if sleep_time > 0:
                        await asyncio.sleep(sleep_time)
                        
            except Exception as e:
                print(f"âŒ åµæ¸¬è¿´åœˆéŒ¯èª¤: {e}")
                await asyncio.sleep(0.1)
    
    def _run_yolo_inference(self, frame):
        """
        åŸ·è¡Œ YOLO æ¨è«– (åŒæ­¥æ–¹æ³•,ä¾› run_in_executor ä½¿ç”¨)
        
        Args:
            frame: è¼¸å…¥å½±åƒ (numpy array)
            
        Returns:
            YOLO Results ç‰©ä»¶
        """
        # å¾ project_config è®€å–è¨­å‚™è¨­å®š
        device = self.project_config.get("yolo_device", {}).get("device", self.config["model"]["device"])
        
        results = self.model.track(
            source=frame,
            classes=[0],  # åªåµæ¸¬äººé¡
            conf=self.config["model"]["conf"],
            iou=self.config["model"]["iou"],
            imgsz=self.config["model"]["imgsz"],
            device=device,
            tracker=self.config["model"]["tracker"],
            persist=True,  # ä¿æŒè¿½è¹¤ ID
            show=False,
            verbose=False
        )
        return results
    
    def _process_results(self, results) -> Dict[str, Any]:
        """
        è™•ç† YOLO åµæ¸¬çµæœ
        
        Args:
            results: YOLO Results ç‰©ä»¶
            
        Returns:
            è™•ç†å¾Œçš„åµæ¸¬è³‡æ–™å­—å…¸
        """
        detections = []
        distances = []
        
        if results[0].boxes is not None and len(results[0].boxes) > 0:
            for box in results[0].boxes:
                # å–å¾—é‚Šç•Œæ¡†è³‡æ–™
                xyxy = box.xyxy[0].cpu().numpy()
                x1, y1, x2, y2 = xyxy
                box_height = y2 - y1
                box_width = x2 - x1
                
                # å–å¾—è¿½è¹¤ ID
                track_id = int(box.id[0]) if box.id is not None else None
                
                # è¨ˆç®—è·é›¢
                distance = self.distance_calculator.calculate_distance(
                    box_height, box_width, track_id
                )
                distances.append(distance)
                
                # å–å¾—ä¿¡å¿ƒåº¦
                confidence = float(box.conf[0])
                
                # çµ„è£åµæ¸¬è³‡æ–™
                detections.append({
                    "track_id": track_id,
                    "distance": round(distance, 1),
                    "bbox": [float(x1), float(y1), float(x2), float(y2)],
                    "confidence": round(confidence, 3)
                })
        
        # æ›´æ–°çµ±è¨ˆ
        self.total_detections = len(detections)
        self.closest_distance = round(min(distances), 1) if distances else 0.0
        
        return {
            "detections": detections,
            "total_count": self.total_detections,
            "closest_distance": self.closest_distance,
            "fps": self.fps,
            "actual_fps": self.actual_fps
        }
    
    def get_current_snapshot(self) -> Optional[Dict[str, Any]]:
        """
        å–å¾—ç•¶å‰åµæ¸¬çµæœå¿«ç…§ (ä¾› REST API ä½¿ç”¨)
        
        Returns:
            æœ€æ–°çš„åµæ¸¬çµæœ,è‹¥å°šæœªé–‹å§‹åµæ¸¬å‰‡è¿”å› None
        """
        return self.current_snapshot
    
    def get_stats(self) -> Dict[str, Any]:
        """
        å–å¾—çµ±è¨ˆè³‡è¨Š
        
        Returns:
            çµ±è¨ˆè³‡æ–™å­—å…¸
        """
        return {
            "total_count": self.total_detections,
            "closest_distance": self.closest_distance,
            "fps": self.fps,
            "actual_fps": self.actual_fps,
            "is_running": self.is_running,
            "uptime": int(time.time() - self.start_time) if self.start_time else 0
        }
    
    async def reload_config(self):
        """
        é‡æ–°è¼‰å…¥é…ç½®ä¸¦é‡å•Ÿåµæ¸¬å™¨
        ç”¨æ–¼å¾Œå°ä¿®æ”¹ sensor_config.json å¾Œæ‰‹å‹•åˆ·æ–°
        """
        was_running = self.is_running
        
        if was_running:
            await self.stop_detection()
        
        # é‡æ–°è¼‰å…¥é…ç½®
        self.config = load_sensor_config()
        self.project_config = load_project_config()
        self.distance_calculator = DistanceCalculator(self.config["distance"])
        
        if was_running:
            await self.start_detection()
        
        print("ğŸ”„ é…ç½®å·²é‡æ–°è¼‰å…¥")
    
    def calculate_target_resolution(self, distance: float) -> tuple:
        """
        æ ¹æ“šè·é›¢è¨ˆç®—ç›®æ¨™è§£æåº¦
        
        Args:
            distance: åµæ¸¬åˆ°çš„è·é›¢ (cm)
            
        Returns:
            (width, height) å…ƒçµ„
        """
        blur_config = self.project_config.get("blur_control", {})
        distance_config = self.project_config.get("distance_mapping", {})
        
        min_width = blur_config.get("min_resolution_width", 320)
        max_width = blur_config.get("max_resolution_width", 1920)
        min_distance = distance_config.get("min_distance", 50)
        max_distance = distance_config.get("max_distance", 500)
        
        # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°äºº (distance = 0),ä½¿ç”¨æœ€å¤§è§£æåº¦
        if distance == 0:
            width = max_width
        else:
            # é™åˆ¶è·é›¢åœ¨ç¯„åœå…§
            clamped_dist = max(min_distance, min(max_distance, distance))
            
            # ç·šæ€§æ˜ å°„ (è·é›¢è¶Šè¿‘,è§£æåº¦è¶Šä½)
            ratio = (clamped_dist - min_distance) / (max_distance - min_distance)
            width = int(min_width + ratio * (max_width - min_width))
        
        # ä¿æŒ 16:9 æ¯”ä¾‹
        height = int(width * 9 / 16)
        
        # ç¢ºä¿æ˜¯å¶æ•¸ (æŸäº›ç·¨ç¢¼å™¨è¦æ±‚)
        width = width - (width % 2)
        height = height - (height % 2)
        
        return (width, height)
    
    def calculate_target_quality(self, distance: float) -> int:
        """
        æ ¹æ“šè·é›¢è¨ˆç®— JPEG å“è³ª
        è·é›©è¶Šè¿‘ï¼Œå“è³ªè¶Šä½ï¼›è·é›©è¶Šé ï¼Œå“è³ªè¶Šé«˜
        
        Args:
            distance: åµæ¸¬åˆ°çš„è·é›¢ (cm)
            
        Returns:
            JPEG å“è³ª (1-100)
        """
        streaming_config = self.project_config.get("flur_streaming", {})
        distance_config = self.project_config.get("distance_mapping", {})
        
        min_quality = streaming_config.get("min_jpeg_quality", 30)
        max_quality = streaming_config.get("max_jpeg_quality", 85)
        min_distance = distance_config.get("min_distance", 50)
        max_distance = distance_config.get("max_distance", 500)
        
        # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°äºº (distance = 0),ä½¿ç”¨æœ€é«˜å“è³ª
        if distance == 0:
            return max_quality
        
        # é™åˆ¶è·é›¢åœ¨ç¯„åœå…§
        clamped_dist = max(min_distance, min(max_distance, distance))
        
        # ç·šæ€§æ˜ å°„ (è·é›¢è¶Šè¿‘,å“è³ªè¶Šä½)
        ratio = (clamped_dist - min_distance) / (max_distance - min_distance)
        quality = int(min_quality + ratio * (max_quality - min_quality))
        
        # é™åˆ¶åœ¨ 1-100 ç¯„åœ
        return max(1, min(100, quality))
    
    def resize_frame(self, frame: np.ndarray, target_size: tuple) -> Optional[np.ndarray]:
        """
        èª¿æ•´å½±åƒå°ºå¯¸
        
        Args:
            frame: åŸå§‹å½±åƒ
            target_size: ç›®æ¨™å°ºå¯¸ (width, height)
            
        Returns:
            èª¿æ•´å¾Œçš„å½±åƒï¼Œè‹¥å¤±æ•—å‰‡è¿”å› None
        """
        try:
            # é©—è­‰è¼¸å…¥
            if frame is None or frame.size == 0:
                print("âš  resize_frame: å½±åƒç‚ºç©º")
                return None
            
            if not isinstance(target_size, tuple) or len(target_size) != 2:
                print(f"âš  resize_frame: ç„¡æ•ˆçš„ç›®æ¨™å°ºå¯¸ {target_size}")
                return None
            
            width, height = target_size
            if width <= 0 or height <= 0 or width > 4096 or height > 4096:
                print(f"âš  resize_frame: å°ºå¯¸è¶…å‡ºç¯„åœ {width}x{height}")
                return None
            
            # åŸ·è¡Œç¸®æ”¾
            return cv2.resize(frame, target_size, interpolation=cv2.INTER_AREA)
            
        except Exception as e:
            print(f"âŒ resize_frame éŒ¯èª¤: {e}")
            return None
    
    def encode_frame_to_base64(self, frame: np.ndarray, quality: int = 70) -> Optional[str]:
        """
        å°‡å½±åƒå¹€ç·¨ç¢¼ç‚º Base64 å­—ä¸²
        
        Args:
            frame: OpenCV å½±åƒ (numpy array)
            quality: JPEG å£“ç¸®å“è³ª (1-100)ï¼Œé è¨­é™ä½åˆ° 70 ä»¥æå‡é€Ÿåº¦
            
        Returns:
            Base64 ç·¨ç¢¼çš„ JPEG å½±åƒå­—ä¸²ï¼Œè‹¥å¤±æ•—å‰‡è¿”å› None
        """
        try:
            if frame is None or frame.size == 0:
                print("âš  encode_frame_to_base64: å½±åƒç‚ºç©º")
                return None
            
            # é™åˆ¶å“è³ªç¯„åœ
            quality = max(1, min(100, quality))
            
            # å„ªåŒ–ç·¨ç¢¼åƒæ•¸ä»¥æå‡é€Ÿåº¦
            encode_param = [
                int(cv2.IMWRITE_JPEG_QUALITY), quality,
                int(cv2.IMWRITE_JPEG_OPTIMIZE), 0,  # é—œé–‰å„ªåŒ–ä»¥åŠ é€Ÿ
                int(cv2.IMWRITE_JPEG_PROGRESSIVE), 0  # é—œé–‰æ¼¸é€²å¼ä»¥åŠ é€Ÿ
            ]
            success, buffer = cv2.imencode('.jpg', frame, encode_param)
            
            if not success:
                print("âš  encode_frame_to_base64: JPEG ç·¨ç¢¼å¤±æ•—")
                return None
            
            return base64.b64encode(buffer).decode('utf-8')
            
        except Exception as e:
            print(f"âŒ encode_frame_to_base64 éŒ¯èª¤: {e}")
            return None
    
    def get_current_frame_base64(self, quality: int = 70, target_resolution: Optional[tuple] = None) -> Optional[str]:
        """
        å–å¾—ç•¶å‰å½±åƒå¹€çš„ Base64 ç·¨ç¢¼
        
        Args:
            quality: JPEG å£“ç¸®å“è³ª (1-100)
            target_resolution: ç›®æ¨™è§£æåº¦ (width, height)ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨åŸå§‹è§£æåº¦
            
        Returns:
            Base64 ç·¨ç¢¼çš„å½±åƒ,è‹¥ç„¡å½±åƒå‰‡è¿”å› None
        """
        try:
            if self.current_frame is None:
                return None
            
            frame = self.current_frame
            
            # å¦‚æœæŒ‡å®šäº†ç›®æ¨™è§£æåº¦ï¼Œå…ˆç¸®æ”¾å½±åƒ
            if target_resolution is not None:
                frame = self.resize_frame(frame, target_resolution)
                if frame is None:
                    return None
            
            return self.encode_frame_to_base64(frame, quality)
            
        except Exception as e:
            print(f"âŒ get_current_frame_base64 éŒ¯èª¤: {e}")
            return None
    
    def get_frame_with_resolution(self, distance: float, quality: Optional[int] = None, enable_dynamic_quality: bool = False) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ“šè·é›¢å–å¾—å‹•æ…‹è§£æåº¦çš„å½±åƒå¹€
        
        Args:
            distance: åµæ¸¬è·é›¢ (cm)
            quality: JPEG å£“ç¸®å“è³ª (1-100)ï¼Œè‹¥ç‚º None ä¸” enable_dynamic_quality=True å‰‡è‡ªå‹•è¨ˆç®—
            enable_dynamic_quality: æ˜¯å¦å•Ÿç”¨å‹•æ…‹å“è³ª
            
        Returns:
            åŒ…å«å½±åƒå’Œè§£æåº¦è³‡è¨Šçš„å­—å…¸ï¼Œè‹¥ç„¡å½±åƒå‰‡è¿”å› None
        """
        try:
            if self.current_frame is None:
                return None
            
            # è¨ˆç®—ç›®æ¨™è§£æåº¦
            target_resolution = self.calculate_target_resolution(distance)
            
            # è¨ˆç®— JPEG å“è³ª
            if enable_dynamic_quality and quality is None:
                target_quality = self.calculate_target_quality(distance)
            else:
                target_quality = quality if quality is not None else 70
            
            # èª¿æ•´å½±åƒå°ºå¯¸
            resized_frame = self.resize_frame(self.current_frame, target_resolution)
            
            if resized_frame is None:
                print("âš  get_frame_with_resolution: å½±åƒç¸®æ”¾å¤±æ•—")
                return None
            
            # ç·¨ç¢¼ç‚º Base64
            frame_base64 = self.encode_frame_to_base64(resized_frame, target_quality)
            
            return {
                "image": frame_base64,
                "resolution": {
                    "width": target_resolution[0],
                    "height": target_resolution[1]
                },
                "quality": target_quality
            }
            
        except Exception as e:
            print(f"âŒ get_frame_with_resolution éŒ¯èª¤: {e}")
            return None
