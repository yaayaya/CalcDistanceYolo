#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO åµæ¸¬æœå‹™ - æ ¸å¿ƒåµæ¸¬å¼•æ“
"""

import asyncio
import cv2
import time
import base64
import numpy as np
from collections import deque
from typing import Optional, Dict, Any, AsyncGenerator
from ultralytics import YOLO

from .calculator import DistanceCalculator
from ..utils.config_loader import load_sensor_config, get_model_path, load_project_config


class YOLODetectorService:
    """
    YOLO11 åµæ¸¬æœå‹™
    è² è²¬æ”å½±æ©Ÿç®¡ç†ã€YOLO æ¨è«–ã€è·é›¢è¨ˆç®—
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åµæ¸¬æœå‹™"""
        self.config = load_sensor_config()
        self.project_config = load_project_config()
        self.model: Optional[YOLO] = None
        self.cap: Optional[cv2.VideoCapture] = None
        self.is_running = False
        
        # è·é›¢è¨ˆç®—å™¨
        self.distance_calculator = DistanceCalculator(self.config["distance"])
        
        # çµ±è¨ˆè³‡æ–™
        self.fps = 0
        self.actual_fps = 0
        self.total_detections = 0
        self.closest_distance = 0.0
        self.frame_times = deque(maxlen=30)
        self.start_time: Optional[float] = None
        
        # ç•¶å‰åµæ¸¬çµæœå¿«ç…§ (ä¾› REST API ä½¿ç”¨)
        self.current_snapshot: Optional[Dict[str, Any]] = None
        
        # æœ€æ–°å½±åƒå¹€ (ä¾› Flur ä¸²æµä½¿ç”¨)
        self.current_frame: Optional[np.ndarray] = None
        
    def load_model(self):
        """è¼‰å…¥ YOLO æ¨¡å‹"""
        if self.model is not None:
            return
            
        try:
            model_path = get_model_path()
            self.model = YOLO(str(model_path))
            
            # å¾ project_config è®€å–è¨­å‚™è¨­å®š
            device = self.project_config.get("yolo_device", {}).get("device", "cpu")
            print(f"âœ… YOLO æ¨¡å‹å·²è¼‰å…¥: {model_path} (è¨­å‚™: {device})")
        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•è¼‰å…¥ YOLO æ¨¡å‹: {e}")
    
    def start_camera(self):
        """å•Ÿå‹•æ”å½±æ©Ÿ"""
        if self.cap is not None and self.cap.isOpened():
            return
            
        try:
            source = self.config["camera"]["source"]
            self.cap = cv2.VideoCapture(source)
            
            if not self.cap.isOpened():
                raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ: {source}")
            
            # è¨­å®šè§£æåº¦
            width = self.config["camera"]["width"]
            height = self.config["camera"]["height"]
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            
            print(f"âœ… æ”å½±æ©Ÿå·²å•Ÿå‹•: {source} ({width}x{height})")
        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•å•Ÿå‹•æ”å½±æ©Ÿ: {e}")
    
    def stop_camera(self):
        """åœæ­¢æ”å½±æ©Ÿ"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
            print("â¹ æ”å½±æ©Ÿå·²åœæ­¢")
    
    async def start_detection(self):
        """å•Ÿå‹•åµæ¸¬"""
        if self.is_running:
            return
            
        self.load_model()
        self.start_camera()
        self.is_running = True
        self.start_time = time.time()
        print("â–¶ åµæ¸¬å™¨å·²å•Ÿå‹•")
    
    async def stop_detection(self):
        """åœæ­¢åµæ¸¬"""
        self.is_running = False
        self.stop_camera()
        self.start_time = None
        print("â¹ åµæ¸¬å™¨å·²åœæ­¢")
    
    async def detection_stream(self) -> AsyncGenerator[Dict[str, Any], None]:
        """
        åµæ¸¬ä¸²æµ - ç•°æ­¥ç”Ÿæˆå™¨
        æŒçºŒç”¢ç”Ÿåµæ¸¬çµæœç›´åˆ° is_running ç‚º False
        
        Yields:
            åµæ¸¬çµæœå­—å…¸,åŒ…å« detections, fps, closest_distance, total_count, timestamp
        """
        if not self.is_running:
            await self.start_detection()
        
        frame_count = 0
        fps_start = time.time()
        fps_counter = 0
        last_frame_time = time.time()
        
        # FPS é™åˆ¶åƒæ•¸
        use_fps_limit = self.config["performance"]["use_fps_limit"]
        target_fps = self.config["performance"]["target_fps"]
        frame_interval = 1.0 / target_fps if use_fps_limit else 0
        vid_stride = self.config["model"]["vid_stride"]
        
        loop = asyncio.get_event_loop()
        
        while self.is_running:
            try:
                loop_start = time.time()
                
                # === è®€å–å½±åƒ (åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œ,é¿å…é˜»å¡) ===
                ret, frame = await loop.run_in_executor(None, self.cap.read)
                
                if not ret:
                    print("âš  ç„¡æ³•è®€å–å½±åƒ,å˜—è©¦é‡æ–°é€£æ¥...")
                    await asyncio.sleep(1)
                    continue
                
                # å„²å­˜ç•¶å‰å¹€ä¾› Flur ä¸²æµä½¿ç”¨
                self.current_frame = frame.copy()
                
                frame_count += 1
                
                # === è·³å¹€è™•ç† ===
                if frame_count % vid_stride != 0:
                    continue
                
                # === YOLO æ¨è«– (åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œ) ===
                results = await loop.run_in_executor(
                    None,
                    self._run_yolo_inference,
                    frame
                )
                
                # === è™•ç†åµæ¸¬çµæœ ===
                detection_data = self._process_results(results)
                
                # === FPS è¨ˆç®— ===
                fps_counter += 1
                if time.time() - fps_start >= 1.0:
                    self.fps = fps_counter
                    fps_counter = 0
                    fps_start = time.time()
                
                # === å¯¦éš› FPS (å«è™•ç†æ™‚é–“) ===
                frame_time = time.time() - last_frame_time
                self.frame_times.append(frame_time)
                avg_frame_time = np.mean(self.frame_times)
                self.actual_fps = int(1.0 / avg_frame_time) if avg_frame_time > 0 else 0
                last_frame_time = time.time()
                
                # === æ›´æ–°çµ±è¨ˆè³‡æ–™ ===
                detection_data["fps"] = self.fps
                detection_data["actual_fps"] = self.actual_fps
                detection_data["timestamp"] = time.time()
                
                # æ›´æ–°å¿«ç…§
                self.current_snapshot = detection_data
                
                # === ç”¢ç”Ÿçµæœ ===
                yield detection_data
                
                # === FPS é™åˆ¶ ===
                if use_fps_limit:
                    elapsed_time = time.time() - loop_start
                    sleep_time = frame_interval - elapsed_time
                    if sleep_time > 0:
                        await asyncio.sleep(sleep_time)
                        
            except Exception as e:
                print(f"âŒ åµæ¸¬è¿´åœˆéŒ¯èª¤: {e}")
                await asyncio.sleep(0.1)
    
    def _run_yolo_inference(self, frame):
        """
        åŸ·è¡Œ YOLO æ¨è«– (åŒæ­¥æ–¹æ³•,ä¾› run_in_executor ä½¿ç”¨)
        
        Args:
            frame: è¼¸å…¥å½±åƒ (numpy array)
            
        Returns:
            YOLO Results ç‰©ä»¶
        """
        # å¾ project_config è®€å–è¨­å‚™è¨­å®š
        device = self.project_config.get("yolo_device", {}).get("device", self.config["model"]["device"])
        
        results = self.model.track(
            source=frame,
            classes=[0],  # åªåµæ¸¬äººé¡
            conf=self.config["model"]["conf"],
            iou=self.config["model"]["iou"],
            imgsz=self.config["model"]["imgsz"],
            device=device,
            tracker=self.config["model"]["tracker"],
            persist=True,  # ä¿æŒè¿½è¹¤ ID
            show=False,
            verbose=False
        )
        return results
    
    def _process_results(self, results) -> Dict[str, Any]:
        """
        è™•ç† YOLO åµæ¸¬çµæœ
        
        Args:
            results: YOLO Results ç‰©ä»¶
            
        Returns:
            è™•ç†å¾Œçš„åµæ¸¬è³‡æ–™å­—å…¸
        """
        detections = []
        distances = []
        
        if results[0].boxes is not None and len(results[0].boxes) > 0:
            for box in results[0].boxes:
                # å–å¾—é‚Šç•Œæ¡†è³‡æ–™
                xyxy = box.xyxy[0].cpu().numpy()
                x1, y1, x2, y2 = xyxy
                box_height = y2 - y1
                box_width = x2 - x1
                
                # å–å¾—è¿½è¹¤ ID
                track_id = int(box.id[0]) if box.id is not None else None
                
                # è¨ˆç®—è·é›¢
                distance = self.distance_calculator.calculate_distance(
                    box_height, box_width, track_id
                )
                distances.append(distance)
                
                # å–å¾—ä¿¡å¿ƒåº¦
                confidence = float(box.conf[0])
                
                # çµ„è£åµæ¸¬è³‡æ–™
                detections.append({
                    "track_id": track_id,
                    "distance": round(distance, 1),
                    "bbox": [float(x1), float(y1), float(x2), float(y2)],
                    "confidence": round(confidence, 3)
                })
        
        # æ›´æ–°çµ±è¨ˆ
        self.total_detections = len(detections)
        self.closest_distance = round(min(distances), 1) if distances else 0.0
        
        return {
            "detections": detections,
            "total_count": self.total_detections,
            "closest_distance": self.closest_distance,
            "fps": self.fps,
            "actual_fps": self.actual_fps
        }
    
    def get_current_snapshot(self) -> Optional[Dict[str, Any]]:
        """
        å–å¾—ç•¶å‰åµæ¸¬çµæœå¿«ç…§ (ä¾› REST API ä½¿ç”¨)
        
        Returns:
            æœ€æ–°çš„åµæ¸¬çµæœ,è‹¥å°šæœªé–‹å§‹åµæ¸¬å‰‡è¿”å› None
        """
        return self.current_snapshot
    
    def get_stats(self) -> Dict[str, Any]:
        """
        å–å¾—çµ±è¨ˆè³‡è¨Š
        
        Returns:
            çµ±è¨ˆè³‡æ–™å­—å…¸
        """
        return {
            "total_count": self.total_detections,
            "closest_distance": self.closest_distance,
            "fps": self.fps,
            "actual_fps": self.actual_fps,
            "is_running": self.is_running,
            "uptime": int(time.time() - self.start_time) if self.start_time else 0
        }
    
    async def reload_config(self):
        """
        é‡æ–°è¼‰å…¥é…ç½®ä¸¦é‡å•Ÿåµæ¸¬å™¨
        ç”¨æ–¼å¾Œå°ä¿®æ”¹ sensor_config.json å¾Œæ‰‹å‹•åˆ·æ–°
        """
        was_running = self.is_running
        
        if was_running:
            await self.stop_detection()
        
        # é‡æ–°è¼‰å…¥é…ç½®
        self.config = load_sensor_config()
        self.project_config = load_project_config()
        self.distance_calculator = DistanceCalculator(self.config["distance"])
        
        if was_running:
            await self.start_detection()
        
        print("ğŸ”„ é…ç½®å·²é‡æ–°è¼‰å…¥")
    
    def encode_frame_to_base64(self, frame: np.ndarray, quality: int = 85) -> str:
        """
        å°‡å½±åƒå¹€ç·¨ç¢¼ç‚º Base64 å­—ä¸²
        
        Args:
            frame: OpenCV å½±åƒ (numpy array)
            quality: JPEG å£“ç¸®å“è³ª (1-100)
            
        Returns:
            Base64 ç·¨ç¢¼çš„ JPEG å½±åƒå­—ä¸²
        """
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
        _, buffer = cv2.imencode('.jpg', frame, encode_param)
        return base64.b64encode(buffer).decode('utf-8')
    
    def get_current_frame_base64(self, quality: int = 85) -> Optional[str]:
        """
        å–å¾—ç•¶å‰å½±åƒå¹€çš„ Base64 ç·¨ç¢¼
        
        Args:
            quality: JPEG å£“ç¸®å“è³ª (1-100)
            
        Returns:
            Base64 ç·¨ç¢¼çš„å½±åƒ,è‹¥ç„¡å½±åƒå‰‡è¿”å› None
        """
        if self.current_frame is None:
            return None
        
        return self.encode_frame_to_base64(self.current_frame, quality)
